# coding: utf-8

from app import db
from models import User, Problem, Solution, Toolbox, Var, Source, ToolboxDependency, SolutionDependency, License, create_database, drop_tables, index_entry


def bootstrap():
    db.connect()
    drop_tables(db)
    create_database(db)

    user = User.create(name="Fred", email="fred@example.org")

    anuga_problem = Problem.create(
        name="Regional Inundation modelling (storm-surge or tsunamis)",
        description="Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
        author=user
    )
    index_entry(anuga_problem)

    anuga_toolbox = Toolbox.create(
        name="ANUGA",
        description="ANUGA is a tool which can simulate events and their effects as they ‘progress’ or travel through a scenario in a model. You can model the ‘wave’ or storm surge to measure the impact and risk for known locations.",
        author=user,
        homepage="https://anuga.anu.edu.au",
        license=License.create(url="https://anuga.anu.edu.au/svn/anuga/trunk/anuga_core/source/anuga/LICENSE.txt"),
        source=Source.create(
            type="svn",
            url="https://anuga.anu.edu.au/svn/anuga/trunk/anuga_core/"
        )
    )
    ToolboxDependency.create(type="python", path="requirements.txt", entry=anuga_toolbox)
    index_entry(anuga_toolbox)

    anuga_solution = Solution.create(
        name="ANUGA Busselton example",
        description="This template contains a pre-canned event (a wave) entering on the WEST of the grid, heading east, designed for coastal simulations of the Busselton-Bunbury area.\n\nThe implemented solver (Parallel finite volume method for hydrodynamic inundation modelling) is [described here](http://journal.austms.org.au/ojs/index.php/ANZIAMJ/article/view/153/)\n\nAn overview of the solver is [available here](http://www.ga.gov.au/corporate_data/69370/Rec2009_036.pdf).\n\nInputs:\n\nThe template can be customised in a variety of ways \n\n\tXxxx\n\n\tYyyy\n\n\tZzzz\n\nAnd is paired with a DEM of the area in question.\n\n\n\nOutputs:\n\n\tScreenshots of xxx\n\n\tCustom ANUGA SSW (database) of the simulation",
        author=user,
        problem=anuga_problem,
        toolbox=anuga_toolbox,
        homepage="https://github.com/GeoscienceAustralia/tcrm",
        template="\"\"\"Script for running a tsunami inundation scenario for Busselton, WA Australia.\n\nSource data such as elevation and boundary data is assumed to be available in\ndirectories specified by project.py\nThe output sww file is stored in directory named after the scenario, i.e\nslide or fixed_wave.\n\nThe scenario is defined by a triangular mesh created from project.polygon,\nthe elevation data and a tsunami wave generated by a submarine mass failure.\n\nGeoscience Australia, 2004-present\n\"\"\"\n\n\"\"\"ANUGA modelling using portal netCDF data\"\"\"\n\n\n#------------------------------------------------------------------------------\n# Import necessary modules\n#------------------------------------------------------------------------------\n# Standard modules\nimport os\nimport time\nimport sys\nfrom math import sin, pi, exp\nimport numpy as np\nimport VHIRL_conversions\nimport subprocess\nfrom os.path import join, exists\n\n# Related major packages\nimport anuga\n\n######################################################\n####### Do not change anything above this line #######\n\n# Definition of file names and polygons\n\"\"\" Common filenames and locations for topographic data, meshes and outputs.\n    This file defines the parameters of the scenario you wish to run.\n\"\"\"\n\n#------------------------------------------------------------------------------\n# Filenames\n#------------------------------------------------------------------------------\n\n# Filename for input data (NetCDF format)\ndataset = '${input_dataset}'\nname_stem = scenario_name = '${name_stem}'\nmeshname = name_stem + '.msh'\n\n#------------------------------------------------------------------------------\n# Runtime parameters\n#------------------------------------------------------------------------------\nv_cache = False\nv_verbose = True\n\n#------------------------------------------------------------------------------\n# Define scenario as either slide or fixed_wave. Choose one.\n#------------------------------------------------------------------------------\nscenario = 'fixed_wave' # Huge wave applied at the boundary\n\n\n#------------------------------------------------------------------------------\n# Domain definitions\n#------------------------------------------------------------------------------\n# bounding polygon for study area\nbusselton_extent = np.asarray([[357325,6270510],\n                               [344635,6267810],\n                               [314645,6268400],\n                               [286811,6277911],\n                               [286174,6308019],\n                               [293089,6341152],\n                               [344595,6456235],\n                               [389463,6441867],\n                               [392955,6320400],\n                               [379095,6288910]])\n\nzone = 50\nbase_scale = ${base_scale}\ndefault_res = 25 * base_scale   # Background resolution\n\n#------------------------------------------------------------------------------\n# Data for Tides\n#------------------------------------------------------------------------------\nv_tide = ${tide}\n\n\n####### Do not change anything below this line #######\n######################################################\n\njobstart = time.time()\n\n\n# Create ASC from nc data\nVHIRL_conversions.nc2asc(dataset, name_stem, zone=zone)\n\n# Create DEM from asc data\nanuga.asc2dem(name_stem+'.asc', use_cache=v_cache, verbose=v_verbose)\n\n# Create pts file for onshore DEM\nanuga.dem2pts(name_stem+'.dem', use_cache=v_cache, verbose=v_verbose)\n\n#------------------------------------------------------------------------------\n# Create the triangular mesh and domain based on\n# overall clipping polygon with a tagged\n# boundary and interior regions as defined in project.py\n#------------------------------------------------------------------------------\ndomain = anuga.create_domain_from_regions(busselton_extent,\n                                    boundary_tags={'land_sse': [0],\n                                                   'land_s': [1],\n                                                   'bottom': [2],\n                                                   'ocean_wsw': [3],\n                                                   'ocean_w': [4],\n                                                   'ocean_wnw': [5],\n                                                   'top': [6],\n                                                   'land_nne': [7],\n                                                   'land_ese': [8],\n                                                   'land_se': [9]},\n                                    maximum_triangle_area=default_res,\n                                    mesh_filename=meshname,\n                                    use_cache=v_cache,\n                                    verbose=v_verbose)\n\n# Print some stats about mesh and domain\nprint 'Number of triangles = ', len(domain)\nprint 'The extent is ', domain.get_extent()\nprint domain.statistics()\n\n#------------------------------------------------------------------------------\n# Setup parameters of computational domain\n#------------------------------------------------------------------------------\ndomain.set_name('busselton_' + scenario)       # Name of sww file\ndomain.set_datadir('.')                       # Store sww output here\ndomain.set_minimum_storable_height(0.01)      # Store only depth > 1cm\ndomain.set_flow_algorithm('tsunami')\n\n\n\n#------------------------------------------------------------------------------\n# Setup initial conditions\n#------------------------------------------------------------------------------\ntide = v_tide\ndomain.set_quantity('stage', tide)\ndomain.set_quantity('friction', 0.0)\n\n\ndomain.set_quantity('elevation',\n                    filename=name_stem + '.pts',\n                    use_cache=v_cache,\n                    verbose=v_verbose,\n                    alpha=0.1)\n\n\nbounaryStartTime = time.time()\n\n#------------------------------------------------------------------------------\n# Setup boundary conditions\n#------------------------------------------------------------------------------\nprint 'Available boundary tags', domain.get_boundary_tags()\n\n# Mean water level\nBd = anuga.Dirichlet_boundary([tide, 0, 0]) \n\n# Neutral boundary\nBs = anuga.Transmissive_stage_zero_momentum_boundary(domain)\n\n# Define tsunami wave (in metres and seconds).\nthe_wave = lambda t: [(20*np.sin(t*np.pi/(60*10)))*np.exp(-t/600), 0, 0]\nBw = anuga.Time_boundary(domain=domain, function=the_wave)\n\ndomain.set_boundary({'land_sse': Bs,\n                     'land_s': Bs,\n                     'bottom': Bs,\n                     'ocean_wsw': Bw,\n                     'ocean_w': Bw,\n                     'ocean_wnw': Bw,\n                     'top': Bs,\n                     'land_nne': Bs,\n                     'land_ese': Bs,\n                     'land_se': Bs})\n\n\n#------------------------------------------------------------------------------\n# Evolve system through time\n#------------------------------------------------------------------------------\n\nevolveStartTime = time.time()\n\n\n# Save every two mins leading up to wave approaching land\nfor t in domain.evolve(yieldstep=2*60,\n                       finaltime=5000):\n    print domain.timestepping_statistics()\n    print domain.boundary_statistics(tags='ocean_wnw')\n\n# Save every 30 secs as wave starts inundating ashore\nfor t in domain.evolve(yieldstep=60*0.5,\n                       finaltime=7000,\n                       skip_initial_step=True):\n    print domain.timestepping_statistics()\n    print domain.boundary_statistics(tags='ocean_wnw')\n\n\n\n\n#------------------------------------------------------------------------------\n# Upload Result Files to Cloud Storage\n#------------------------------------------------------------------------------\ndef cloudUpload(inFilePath, cloudKey):\n    cloudBucket = os.environ[\"STORAGE_BUCKET\"]\n    cloudDir = os.environ[\"STORAGE_BASE_KEY_PATH\"]\n    queryPath = (cloudBucket + \"/\" + cloudDir + \"/\" + cloudKey).replace(\"//\", \"/\")\n    retcode = subprocess.call([\"cloud\", \"upload\", cloudKey, inFilePath, \"--set-acl=public-read\"])\n    print (\"cloudUpload: \" + inFilePath + \" to \" + queryPath + \" returned \" + str(retcode))\n\n\nuploadStartTime = time.time()\n\n# Upload results\nprint 'Uploading result files'\ncloudUpload(\"${input_dataset}\", \"raw_elevation\")\ncloudUpload(\"${name_stem}_UTM.nc\", \"${name_stem}_UTM.nc\")\ncloudUpload(\"${name_stem}.asc\", \"${name_stem}.asc\")\ncloudUpload(\"${name_stem}.prj\", \"${name_stem}.prj\")\ncloudUpload(\"${name_stem}.dem\", \"${name_stem}.dem\")\ncloudUpload(\"${name_stem}.pts\", \"${name_stem}.pts\")\ncloudUpload(\"${name_stem}.msh\", \"${name_stem}.msh\")\ncloudUpload(\"${name_stem}_fixed_wave.sww\", \"${name_stem}_fixed_wave.sww\")\n\nprint 'If you wish to view your output - please look at anuga-viewer here: http://sourceforge.net/projects/anuga/files/'\n\nprint '''\n---------------\n| Timer Stats |\n---------------\n'''\nprint 'Convert/Fit   : %.2f seconds' %(bounaryStartTime-jobstart)\nprint 'Bounding      : %.2f seconds' %(evolveStartTime-bounaryStartTime)\nprint 'Evolve        : %.2f seconds' %(uploadStartTime-evolveStartTime)\nprint 'Upload        : %.2f seconds' %(time.time()-uploadStartTime)\nprint 'Total time: %.2f seconds' %(time.time()-jobstart)\n"
        )

    Var.create(type="int",
               name="base_scale",
               label="Base Scale",
               default=400000,
               min=1,
               solution=anuga_solution)

    Var.create(type="double",
               name="tide",
               label="Tide",
               default=0.0,
               min=0.0,
               step=0.1,
               solution=anuga_solution)

    Var.create(type="string",
               name="name_stem",
               label="File Name",
               default="busselton",
               solution=anuga_solution)

    Var.create(type="file",
               name="input_dataset",
               label="Input dataset (NetCDF)",
               solution=anuga_solution)
    
    index_entry(anuga_solution)

    tcrm_problem = Problem.create(
        name="Understanding cyclone risk",
        description="Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
        author=user
    )
    index_entry(tcrm_problem)

    tcrm_toolbox = Toolbox.create(
        name="Tropical Cyclone Risk Model",
        description="The Tropical Cyclone Risk Model is a stochastic tropical cyclone model developed by [Geoscience Australia](http://www.ga.gov.au) for estimating the wind hazard from tropical cyclones.",
        author=user,
        homepage="https://github.com/GeoscienceAustralia/tcrm",
        license=License.create(url="https://github.com/GeoscienceAustralia/tcrm/blob/master/LICENSE"),
        source=Source.create(type="git",
                         url="https://github.com/GeoscienceAustralia/tcrm.git",
                         checkout="v1.0rc1",
                         exec="python installer/setup.py build_ext -i")
    )
    ToolboxDependency.create(type="system", name="tk-devel", entry=tcrm_toolbox)
    ToolboxDependency.create(type="system", name="tkinter", entry=tcrm_toolbox)
    ToolboxDependency.create(type="system", name="geos-devel", entry=tcrm_toolbox)
    ToolboxDependency.create(type="system", name="hdf5-devel", entry=tcrm_toolbox)
    ToolboxDependency.create(type="python", path="requirements.txt", entry=tcrm_toolbox)
    index_entry(tcrm_toolbox)

    tcrm_solution = Solution.create(
        name="TCRM example",
        description="""The template allows for numerous fake events (generated from real events) to occur on a target area, allowing us to compute statistics about the likelihood, size, and patterns arising from generating thousands of years worth of events.


Inputs:



Outputs:

	Track files for each cyclone

	Statistics about risk areas""",
        author=user,
        homepage="https://github.com/GeoscienceAustralia/tcrm",
        problem=tcrm_problem,
        toolbox=tcrm_toolbox,
        template="import glob\nimport os\nimport subprocess\nimport tempfile\nimport zipfile\n\nTCRM_DIR=\"/opt/tcrm\"\n\niniString = \"\"\"\n[Actions]\n; TCRM modules to execute\nDataProcess=True\nExecuteStat=True\nExecuteTrackGenerator=True\nExecuteWindfield=True\nExecuteHazard=True\nPlotHazard=True\nPlotData=False\nExecuteEvaluate=False\nDownloadData=True\n\n[DataProcess]\nInputFile=Allstorms.ibtracs_wmo.v03r05.csv\nSource=IBTRACS\nStartSeason=1981\nFilterSeasons=True\n\n[Region]\n; Domain for windfield and hazard calculation\ngridLimit={'xMin':${west-bound-lon},'xMax':${east-bound-lon},'yMin':${south-bound-lat},'yMax':${north-bound-lat}}\ngridSpace={'x':1.0,'y':1.0}\ngridInc={'x':1.0,'y':0.5}\npLocalityID=${locality-id}\nLocalityName=${locality-name}\n\n[StatInterface]\nkdeType=Biweight\nkde2DType=Gaussian\nkdeStep=0.2\n\n[TrackGenerator]\n; NumSimulations=1000\nNumSimulations=${num-simulations}\n; YearsPerSimulation=1\nYearsPerSimulation=${years-per-simulation}\nSeasonSeed=${season-seed}\nTrackSeed=${track-seed}\n;SeasonSeed=403943\n;TrackSeed=89333\n\n[WindfieldInterface]\n;TrackPath=./output/vl/tracks\nMargin=2.0\nResolution=${windfield-interface-resolution}\n;Resolution=0.05\nSource=TCRM\nprofileType=powell\nwindFieldType=kepert\n\n[Hazard]\n; Years to calculate return period wind speeds\n;InputPath=./output/vl/windfield\n;Resolution=0.05\nYears=5,10,20,25,50,100,200,250,500,1000,2000,2500\nMinimumRecords=10\nCalculateCI=False\n\n\n[Input]\nlandmask = input/landmask.nc\nmslpfile = MSLP/slp.day.ltm.nc\ndatasets = IBTRACS,LTMSLP\nMSLPGrid=1,2,3,4,12\n\n[Output]\nPath=./output/vl\n\n[Logging]\nLogFile=./output/vl/log/tcrm.log\nLogLevel=INFO\nVerbose=False\n\n[Process]\nExcludePastProcessed=True\nDatFile=./output/vl/process/dat/tcrm.dat\n\n[RMW]\nGetRMWDistFromInputData=False\nmean=50.0\nsigma=0.6\n\n[TCRM]\n; Output track files settings\nColumns=index,age,lon,lat,speed,bearing,pressure,penv,rmax\nFieldDelimiter=,\nNumberOfHeadingLines=1\nSpeedUnits=kph\nPressureUnits=hPa\n\n[IBTRACS]\n; Input data file settings\nurl = ftp://eclipse.ncdc.noaa.gov/pub/ibtracs/v03r05/wmo/csv/Allstorms.ibtracs_wmo.v03r05.csv.gz\npath = input\nfilename = Allstorms.ibtracs_wmo.v03r05.csv\ncolumns = tcserialno,season,num,skip,skip,skip,date,skip,lat,lon,skip,pressure\nfielddelimiter = ,\nnumberofheadinglines = 3\npressureunits = hPa\nlengthunits = km\ndateformat = %Y-%m-%d %H:%M:%S\nspeedunits = kph\n\n[LTMSLP]\n; MSLP climatology file settings\nURL = ftp://ftp.cdc.noaa.gov/Datasets/ncep.reanalysis.derived/surface/slp.day.1981-2010.ltm.nc\npath = MSLP\nfilename = slp.day.ltm.nc\n\"\"\"\n\ndef cloudUpload(inFilePath, cloudKey):\n    \"\"\"Upload inFilePath to cloud bucket with key cloudKey.\"\"\"\n    cloudBucket = os.environ[\"STORAGE_BUCKET\"]\n    cloudDir = os.environ[\"STORAGE_BASE_KEY_PATH\"]\n    queryPath = (cloudBucket + \"/\" + cloudDir + \"/\" + cloudKey).replace(\"//\", \"/\")\n    retcode = subprocess.call([\"cloud\", \"upload\", cloudKey, inFilePath, \"--set-acl=public-read\"])\n    print (\"cloudUpload: \" + inFilePath + \" to \" + queryPath + \" returned \" + str(retcode))\n\ndef cloudDownload(cloudKey, outFilePath):\n    \"\"\"Downloads the specified key from bucket and writes it to outfile.\"\"\"\n    cloudBucket = os.environ[\"STORAGE_BUCKET\"]\n    cloudDir = os.environ[\"STORAGE_BASE_KEY_PATH\"]\n    queryPath = (cloudBucket + \"/\" + cloudDir + \"/\" + cloudKey).replace(\"//\", \"/\")\n    retcode = subprocess.call([\"cloud\", \"download\",cloudBucket,cloudDir,cloudKey, outFilePath])\n    print \"cloudDownload: \" + queryPath + \" to \" + outFilePath + \" returned \" + str(retcode)\n\n# Write the config file\nini_file = tempfile.NamedTemporaryFile(mode='w',\n                                       suffix=\".ini\",\n                                       prefix=\"vhirl-tcrm\",\n                                       delete=False)\nwith ini_file as f:\n    f.write(iniString)\n\n# Execute TCRM job\nprint \"Executing TCRM in {0}\".format(TCRM_DIR)\nos.chdir(TCRM_DIR)\nsubprocess.call([\"mpirun\", \"-np\", \"${n-threads}\", \"/usr/bin/python\", \"tcrm.py\", \"-c\", ini_file.name])\n\n\n# Upload results\ndef upload_results(spec, keyfn=None):\n    \"\"\"Upload files specified by spec.\n\n    Spec will be passed to glob.glob to find files.  If keyfn is\n    supplied it should be a function that takes a filename from glob\n    and returns the corresponding cloud key to use.\n\n    \"\"\"\n    files = glob.glob(spec)\n    for f in files:\n        k = None\n        if keyfn:\n            k = keyfn(f)\n        if k is None:\n            k = f\n        cloudUpload(f, k)\n\n\n# Zip then upload results\ndef zip_upload_results(spec, name, key=None):\n    \"\"\"Zip files globbed from spec into zipfile name and upload under key.\n\n    If key is None it will default to <name>.zip.\n\n    \"\"\"\n    z = zipfile.ZipFile(name, 'w')\n    for f in glob.glob(spec):\n        z.write(f)\n    z.close()\n    cloudUpload(name, name if key is None else key)\n\n\n# Logs\nupload_results(\"output/vl/log/*\")\n# Track files\nzip_upload_results(\"output/vl/tracks/*.csv\", \"tracks.zip\")\n# Windfield files\nzip_upload_results(\"output/vl/windfield/*.nc\", \"windfields.zip\")\n# Hazard data and plots\nupload_results(\"output/vl/plots/hazard/*.png\")\nupload_results(\"output/vl/hazard/*.nc\")"
    )

    Var.create(
        name="east-bound-lon",
        label="East Bound Longitude",
        type="double",
        default=124.0,
        solution=tcrm_solution)
    Var.create(
        name="west-bound-lon",
        label="West Bound Longitude",
        type="double",
        default=113.0,
        solution=tcrm_solution)
    Var.create(
        name="north-bound-lat",
        label="North Bound Latitude",
        type="double",
        default=-15.0,
        solution=tcrm_solution)
    Var.create(
        name="south-bound-lat",
        label="South Bound Latitude",
        type="double",
        default=-26.0,
        solution=tcrm_solution)
    Var.create(
        name="locality-id",
        label="Locality ID",
        type="int",
        values=[250913860],
        solution=tcrm_solution)
    Var.create(
        name="locality-name",
        label="Locality Name",
        type="string",
        values=["Port Hedland"],
        solution=tcrm_solution)
    Var.create(
        name="num-simulations",
        label="Number of simulations",
        type="int",
        default=1000,
        solution=tcrm_solution)
    Var.create(
        name="years-per-simulation",
        label="Years per simulation",
        type="int",
        default=1,
        solution=tcrm_solution)
    Var.create(
        name="season-seed",
        label="Random seed for season",
        type="random-int",
        min=1,
        max=10000000,
        solution=tcrm_solution)
    Var.create(
        name="track-seed",
        label="Random seed for track",
        type="random-int",
        min=1,
        max=10000000,
        solution=tcrm_solution)
    Var.create(
        name="windfield-interface-resolution",
        label="Windfield Resolution",
        type="double",
        default=0.05,
        min=0.02,
        max=0.5,
        step=0.01,
        solution=tcrm_solution)
    Var.create(
        name="n-threads",
        label="Max threads",
        type="int",
        min=1,
        solution=tcrm_solution)

    index_entry(tcrm_solution)
